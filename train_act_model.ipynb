{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3Cvi-mPwKou",
    "outputId": "2b8ec033-b8a2-4a88-b65e-55f5891d0bf4"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/huggingface/lerobot.git\n",
    "%cd lerobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdREBUEttiHA",
    "outputId": "c0d6b49f-c136-4fc1-ab60-4460034a9960"
   },
   "outputs": [],
   "source": [
    "# lerobot source code is built with old versions of PyTorch, which doesn't\n",
    "# support latest Nvidia GPU and CUDA. Update pyproject.toml to install latest\n",
    "# PyTorch versions\n",
    "import re\n",
    "import os\n",
    "\n",
    "def patch_pyproject(file_path=\"pyproject.toml\"):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: {file_path} not found.\")\n",
    "        return\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Define the exact new strings you want inside the first set of quotes\n",
    "    updates = {\n",
    "        \"torch\": \"torch>=2.2.1\",\n",
    "        \"torchcodec\": \"torchcodec>=0.2.1\",\n",
    "        \"torchvision\": \"torchvision>=0.21.0\"\n",
    "    }\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        patched_line = line\n",
    "        for package, new_full_string in updates.items():\n",
    "            # This regex looks for the package name inside quotes and replaces\n",
    "            # EVERYTHING inside those specific quotes up to the first ';' or the end quote.\n",
    "            # It handles multiple comma-separated constraints by wiping them out.\n",
    "            pattern = rf'\"{package}[^a-zA-Z].*'\n",
    "            replacement = f'\"{new_full_string}\",'\n",
    "            patched_line = re.sub(pattern, replacement, patched_line)\n",
    "        new_lines.append(patched_line)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "    print(\"Cleanly patched pyproject.toml and removed legacy constraints.\")\n",
    "\n",
    "patch_pyproject()\n",
    "\n",
    "!git diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doTNrUOvtio2",
    "outputId": "bd9a07b1-dcdc-4214-8330-7ce38d1f714b"
   },
   "outputs": [],
   "source": [
    "# Install the library in editable mode with training dependencies\n",
    "!apt update && apt install -y ffmpeg\n",
    "!pip install \"torch==2.10.0\" \\\n",
    "    \"torchvision>=0.21.0\" \\\n",
    "    \"torchcodec==0.10.0\" \\\n",
    "    \"transformers==4.57.6\" \\\n",
    "    --extra-index-url https://download.pytorch.org/whl/cu130\n",
    "!pip install -e .\n",
    "!pip install wandb  # Highly recommended for monitoring your FLL progress\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UMSNmIv7drF",
    "outputId": "e2c0e8ee-569c-4546-e2fd-ea832e5ff3d2"
   },
   "outputs": [],
   "source": [
    "# Setting up env\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def get_secret(key_name):\n",
    "    # 1. Try Google Colab userdata (Secret Manager)\n",
    "    if 'google.colab' in sys.modules:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            return userdata.get(key_name)\n",
    "        except Exception:\n",
    "            pass # Fallback if secret not found in Colab\n",
    "            \n",
    "    # 2. Try Local/WSL .env file\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    # 3. Fallback to standard environment variable (os.environ)\n",
    "    return os.getenv(key_name)\n",
    "\n",
    "# Usage\n",
    "HF_TOKEN = get_secret('HF_TOKEN')\n",
    "WANDB_API_KEY = get_secret('WANDB_API_KEY')\n",
    "\n",
    "# Apply to environment so libraries find them automatically\n",
    "if HF_TOKEN:\n",
    "    # HUGGINGFACE env\n",
    "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "    from huggingface_hub import login\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"login to hf\")\n",
    "else:\n",
    "    print(\"login to hf failed\")\n",
    "\n",
    "if WANDB_API_KEY:\n",
    "    os.environ['WANDB_API_KEY'] = WANDB_API_KEY    \n",
    "    # WANDB env\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    print(\"login to wandb\")\n",
    "else:\n",
    "    print(\"login to wandb failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrIGMU4xQ8c3"
   },
   "outputs": [],
   "source": [
    "# Prepare training data set. Combine multiple batches under one training data.\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "# Ensure Hugging Face login is done, if not already\n",
    "# login(token=userdata.get('HF_TOKEN')) # Uncomment if not logged in already\n",
    "\n",
    "# Generate input_datasets using a loop\n",
    "input_datasets = [f'fanaustinca/fll_diffusion_v2_batch_{i:02d}' for i in range(1, 4)]\n",
    "\n",
    "output_dataset_name = 'fanaustinca/fll_training_150episodes'\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "datasets_list = []\n",
    "for dataset_name in input_datasets:\n",
    "    print(f\"  Loading {dataset_name}\")\n",
    "    dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "    # Assuming the dataset is a DatasetDict and we want to combine the 'train' split\n",
    "    # Adjust if your dataset structure is different (e.g., just a Dataset object)\n",
    "    if 'train' in dataset:\n",
    "        datasets_list.append(dataset['train'])\n",
    "    else:\n",
    "        datasets_list.append(dataset)\n",
    "\n",
    "# Concatenate datasets\n",
    "print(\"Concatenating datasets...\")\n",
    "combined_dataset = concatenate_datasets(datasets_list)\n",
    "\n",
    "# Push to Hugging Face Hub\n",
    "print(f\"Pushing combined dataset to {output_dataset_name}...\")\n",
    "combined_dataset.push_to_hub(output_dataset_name, private=False)\n",
    "print(\"Dataset combined and pushed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWTgWpy60PN9",
    "outputId": "9f78f520-b99c-4d15-fab5-b842c4ba85c8"
   },
   "outputs": [],
   "source": [
    "# Adjust the following variables before starting training\n",
    "tag = '150episodes'\n",
    "hf_namespace = 'fanaustinca'\n",
    "training_repo = f\"{hf_namespace}/fll_combined_150episodes\"\n",
    "model_repo = f\"{hf_namespace}/fll_act_model_150episodes\"\n",
    "# Use 'local_output' consistently\n",
    "local_output = f\"outputs/model/{model_repo}\"\n",
    "steps = 150000\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "# Clean up output from last run\n",
    "!rm -rf {local_output}\n",
    "\n",
    "\"\"\"\n",
    "tfs_config = [\n",
    "    dict(type=\"ToImage\"),\n",
    "    dict(type=\"RandomAffine\", degrees=0, translate=(0.05, 0.05), fill=0),\n",
    "    dict(type=\"ColorJitter\", brightness=.2, contrast=.2, saturation=.2, hue=.05),\n",
    "    dict(type=\"ConvertImageDtype\", dtype=\"float32\"),\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "tfs_config = {\n",
    "  \"to_tensor\": {\"type\": \"ToImage\"},\n",
    "  \"affine\": {\n",
    "    \"type\": \"RandomAffine\",\n",
    "    \"kwargs\": {\"degrees\": 0, \"translate\": [0.05, 0.05]}\n",
    "  },\n",
    "  \"jitter\": {\n",
    "    \"type\": \"ColorJitter\",\n",
    "    \"kwargs\": {\"brightness\": 0.1, \"contrast\": 0.1, \"saturation\": 0.1, \"hue\": 0.05}\n",
    "  }\n",
    "}\n",
    "\n",
    "# Convert to a compact JSON string for the CLI\n",
    "import json\n",
    "tfs_string = json.dumps(tfs_config, separators=(',', ':'))\n",
    "\n",
    "!python src/lerobot/scripts/lerobot_train.py \\\n",
    "    --policy.type=act \\\n",
    "    --dataset.repo_id={training_repo} \\\n",
    "    --job_name=flamebots_act_training \\\n",
    "    --output_dir={local_output} \\\n",
    "    --policy.n_action_steps=100 \\\n",
    "    --policy.device=cuda \\\n",
    "    --steps={steps} \\\n",
    "    --save_freq=5000 \\\n",
    "    --batch_size={batch_size} \\\n",
    "    --log_freq=1000 \\\n",
    "    --num_workers={num_workers} \\\n",
    "    --dataset.image_transforms.enable=true \\\n",
    "    --dataset.image_transforms.random_order=true \\\n",
    "    --dataset.image_transforms.tfs='{tfs_string}' \\\n",
    "    --policy.use_amp=true \\\n",
    "    --policy.push_to_hub=true \\\n",
    "    --policy.repo_id={model_repo} \\\n",
    "    --wandb.enable=true\n",
    "\n",
    "#!hf repo tag create {model_repo} {tag} -m \"Diffusion model trained on {training_repo}, tag {tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
