{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z3Cvi-mPwKou",
        "outputId": "3c17df07-3f5a-46ef-95c1-d3591bde7bd1"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/huggingface/lerobot.git\n",
        "%cd lerobot\n",
        "\n",
        "# Install the library in editable mode with training dependencies\n",
        "!pip install \"transformers==4.57.6\"\n",
        "!pip install -e .\n",
        "!pip install wandb  # Highly recommended for monitoring your FLL progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UMSNmIv7drF",
        "outputId": "39862360-0510-4625-94b9-3dd61bc8dd25"
      },
      "outputs": [],
      "source": [
        "# Setting up env\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# WANDB env\n",
        "import wandb\n",
        "os.environ[\"WANDB_API_KEY\"] = userdata.get('WANDB_API_KEY')\n",
        "wandb.login()\n",
        "print(\"login to wandb\")\n",
        "\n",
        "# HUGGINGFACE env\n",
        "from huggingface_hub import login\n",
        "login(token=userdata.get('HF_TOKEN'))\n",
        "print(\"login to hf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWTgWpy60PN9",
        "outputId": "b5c6b289-fe48-42b4-fa1c-9d27daddd8b1"
      },
      "outputs": [],
      "source": [
        "# Adjust the following variables before starting training\n",
        "tag = \"350episodes\"\n",
        "hf_namespace = 'fanaustinca'\n",
        "training_repo = f\"{hf_namespace}/fll_training_combined\"\n",
        "model_repo = f\"{hf_namespace}/fll_diffusion_model_colab\"\n",
        "# Use 'local_output' consistently\n",
        "local_output = f\"outputs/model/{model_repo}\"\n",
        "steps = 1000\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "\n",
        "# Clean up output from last run\n",
        "!rm -rf {local_output}\n",
        "\n",
        "!python src/lerobot/scripts/lerobot_train.py \\\n",
        "    --policy.type=diffusion \\\n",
        "    --dataset.repo_id={training_repo} \\\n",
        "    --dataset.revision={tag} \\\n",
        "    --job_name=flamebots_training \\\n",
        "    --output_dir={local_output} \\\n",
        "    --policy.device=cuda \\\n",
        "    --steps={steps} \\\n",
        "    --save_freq=1000 \\\n",
        "    --batch_size={batch_size} \\\n",
        "    --log_freq=1000 \\\n",
        "    --num_workers={num_workers} \\\n",
        "    --policy.use_amp=true \\\n",
        "    --policy.push_to_hub=true \\\n",
        "    --policy.repo_id={model_repo} \\\n",
        "    --wandb.enable=true\n",
        "\n",
        "#!hf repo tag create {model_repo} {tag} -m \"Diffusion model trained on {training_repo}, tag {tag}\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
